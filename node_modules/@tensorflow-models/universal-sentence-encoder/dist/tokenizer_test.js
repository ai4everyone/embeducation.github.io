"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
var tf = require("@tensorflow/tfjs");
var jasmine_util_1 = require("@tensorflow/tfjs-core/dist/jasmine_util");
var test_util_1 = require("./test_util");
var tokenizer_1 = require("./tokenizer");
jasmine_util_1.describeWithFlags('Universal Sentence Encoder tokenizer', tf.test_util.NODE_ENVS, function () {
    var tokenizer;
    beforeAll(function () {
        tokenizer =
            new tokenizer_1.Tokenizer(test_util_1.stubbedTokenizerVocab);
    });
    it('basic usage', function () {
        expect(tokenizer.encode('Ilikeit.')).toEqual([11, 15, 16, 10]);
    });
    it('handles whitespace', function () {
        expect(tokenizer.encode('I like it.')).toEqual([11, 12, 13, 10]);
    });
    it('should normalize inputs', function () {
        expect(tokenizer.encode('Ã§a')).toEqual(tokenizer.encode('c\u0327a'));
    });
    it('should handle unknown inputs', function () {
        expect(function () { return tokenizer.encode('ðŸ˜¹'); }).not.toThrow();
    });
    it('should treat consecutive unknown inputs as a single word', function () {
        expect(tokenizer.encode('aðŸ˜¹ðŸ˜¹')).toEqual([7, 0]);
    });
});
//# sourceMappingURL=tokenizer_test.js.map